 NLALR (NON-CANONICAL LALR) PARSING WITH GRAMMAR TRANSFORMATIONS
  
 The 4 grammars in this folder are test grammars designed for demonstrating typical limitations of LALR(1) parser and
 to show how switching to non-canonical variation (NLALR) can successfully solve the problems. 
 Non-canonical parser allows non-terminals to be used as lookaheads (see the end of this file for more info). 

 All grammars in this folder implement the same language, but non-terminals arrangement is different. 
 A valid program for the language consists of multiple declarations of properties, fields and methods - similar but
  simplified versions of c# constructs. Here is a sample program:
  
    public static int myField;
    private string MyProperty {}
    public virtual string MyMethod();
  
  Grammars:
    #1 - a straighforward implementation of the language, non-parsable by LALR or NLALR
    #2 - restructured grammar #1, with extra non-terminals working as non-canonical lookaheads. NLALR-parsable
    #3 - identical to #1, expcept WrapTail() hints were added, so Irony can restructure it automatically. NLALR parsable
    #4 - more complex case of non-terminal arrangements, with hints added. NLALR-parsable. 

  The problem LALR parser has with grammars like #1 is typical for LALR parsers - using a single token as a lookahead is not
  enough to resolve ambiguities and to select a proper action for already consumed input. Look at simple program above. 
  In our simple language the three statement types - property, field and method - all start
  with a list of modifiers (private, static, etc). The exact lists of modifiers is different for 
  eash statement type. but they have some words in common, for ex "public". This is a typical situation for "c" family 
  of languages (c#, java).

  To define the statement structure in BNF grammar, the grammar writer naturally starts with defining three non-terminals 
  (FieldMod, PropMod, MethodMod) for modifiers, defines the lists of symbols for each, and then creates non-terminals 
  representing lists of these modifiers. That's exactly how it's done in grammar #1. 
  The trouble for the parser comes right after it reads the first shared modifier like "public" - it runs into 
  a reduce-reduce conflict:
  
    FieldMod -> public .
    PromMod -> public .
    MethodMod -> public .
  
  The type of non-terminal modifier to reduce to (FieldMod, PropMod, or MethodMod) is defined by statement type, 
  which may be determined only when it reads past the Name of the property/field/method and see what follows. 
  If it is semicolon, then we have field definition, if it is "{" then it is a property, and "(" means method. 
  If you load grammar #1 and select LALR parsing method in Grammar Explorer, you will see error messages about 
  these reduce-reduce conflicts. 

  To correctly decide which alternative to use, the parser must run ahead and "preview" the first token after Name. 
  This would requires grammar designer to implement some custom assistance method that intercepts in the conflicting state
  and scans tokens ahead trying to determine the statement type and advise the parser. (similar thing is done in demo c# grammar 
  for "<" symbol). The alternative method implemented in so-called GLR parsers is to follow all three parsing paths, 
  effectively running three parsers in parallel.
  The question is - can we improve our parser to resolve this kind of conflict automatically? It appears that it is possible. 

  We need to do the following:
  Fist, we change parser to be non-canonical, meaning that the lookaheads can be both terminals and non-terminals, unlike canonical
  (standard) LALR parser which allows only terminals as lookaheds. 
  Secondly, we modify our grammar so that the Reduce items in the conflicting state now have distinguishing 
  non-terminal lookaheads. We need to create new non-terminals that wrap the ending parts of statements. For example, the field 
  definition (shown in Irony c#-based notation):
     
     FieldDef.Rule = FieldMods + Id + Id + ";" ;   
  
  should be changed to:
    
     FieldDef.Rule = FieldMods + FieldTail;
     FieldTail.Rule = Id + Id + ";";
  
  Essentially the FieldTail non-terminal encloses all the following context, and "brings it back" to the point where we need to decide 
  about reduction of the modifier. Non-canonical parser can now distinguish between alternatives after it reads "public" by moving 
  forward, reading and reducing one of -Tail non-terminals, and then reducing the modifier to FieldMod, PropMod or MethodMod. 
  This grammar transformation is done in grammar #2. If you try processing it using LALR method, you would still get error messages
  about conflict, but if you switch to NLALR then no errors are reported.
  If there are no available non-terminals that can be used as lookaheads, then NLALR parser cannot resolve the conflict.  
  If a lookahead cannot be reduced to something bigger then we call it  fully-reduced lookahead. This is the case for grammar #1, 
  where conflicting lookahead Id (terminal) is fully reduced. 

  The solution presented by grammar #2 involves modifying the original grammar by hand. Can it be done automatically? 
  Certainly yes, Irony can do it. If we identify the places where to introduce new wrapping non-terminals 
  using some grammar hint, then parser can create non-terminals automatically, so NLALR parser would be able to resolve the conflict. So Irony defines new grammar hint and 
  a helper method for producing them WrapTail() that grammar writer can use to identify the tails that need to be wrapped. 
  Better than that - Irony identifies all these places for you. When Grammar Explorer analyzes the grammar with NLALR parse method 
  and finds conflicts that can be fixed by adding WrapTail() instructions, it shows you an advise message in Grammar Errors page. 
  Grammar #3 is essentially identical to original grammar #1, except hints are added following Irony's recommendations. 
  The grammar is accepted by NLALR parser which finds no problems with it. When you load it in Grammar Explorer have a look
  at Non-terminals list to see the extra non-terminals created by parser builder. 

  The grammar #4 is a more complex case, when tail wrapping has to be performed several times. It demonstrates that this 
  approach works in more complex cases, when initial tail wrapping brings new conflicts. Have a look at the grammar #3 - 
  it defines Header non-terminals that wrap the modifier and the following identifier ("type" name). Essentially, the real
  context that resolves the conflict (finishing token ";", "(" or "{") is hidden beyond the current parent non-terminal (-Header). 
  In this case, the tail to be wrapped is just an Id, and after we introduce the first set of tail non-terminals (by adding hints),
  these identifiers have identical expressions - just single Id. This resolves original conflict for modifiers reduction, 
  but brings in new conflicts on new tail non-terminals:
  
      FieldHeader_tail -> Id .
      PropHeader_tail -> Id .
      MethHeader_tail -> Id .
  
  
  We have to add another set of hints to wrap more tails after these, and this finally resolves 
  all conflicts. To see it in action, just remove all WrapTail() calls from grammar #4, and load it into Grammar explorer. 
  You will see advices on adding 3 hints - add them, load grammar again, with new advice. After you add these, grammar 
  is accepted by NLALR method without problems.  
     
  Naturally comes the question - if Irony knows where to add WrapTail hints, and knows how to wrap tails once the hints are 
  added, why can't it do altogether automatically? I've actually tried initially to implement it this way, but it didn't work well.
  The problem is that grammar analyzer identifies the tails that need to be wrapped AFTER it creates LALR automaton, 
  and if it restructures the grammar at this point, it has to rebuild the automaton again because the grammar changed, 
  which can bring new conflicts and new tails to be wrapped, and so on. The process ends eventually, but it make take considerable
  time for more complex grammars, for which constructing LALR automaton may take hundreds of milliseconds.
  
  So I decided it to use sem-automated solution: Irony advises you where to put hints, and once they are in place 
  Irony does all restructuring automatically. One advantage of using hints vs manual restructuring is that 
  you don't have to mess up the grammar structure just to go around the parser limitations. 
  
  This algorithm of automatic grammar restructuring with NLALR automaton is still in research phase, it doesn't yet work 
  well for big and messy grammars like c# demo grammar in Irony samples. I'm not sure why - because of all adjustments I've 
  made to original grammar previously to fit it to LALR parsing, or because of some bug in implementation of some flaw 
  in NLALR construction algorithm. I need to research further - I have some more ideas how to improve things, 
  so expect more to come.
  
  The ultimate goal is to build a parsing algorithm that does not have internal limitations that manifest in conflicts
  due to parsing method, and therefore accepts any inambigous grammar. A big goal, I know, but it's worth trying. 
  If we get there, then language implementors finally won't have to worry about parser limitations - just build 
  inambigous grammar, and parser will take care of everything. 
  
  ABOUT NON-CANONICAL PARSERS
  The non-canonical parser allows non-terminal lookaheads and does not strictly follow the right-most derivation rule of canonical LR/LALR parser. 
  For example, when parsing expression 'AB' where both A and B are non-terminals, the canonical LALR parser always reduces A first, 
  and then reduces B. When reducing A it uses a single token lookahead which is a start of B. 
  Non-canonical parser can first reduce B, then come back and reduce A, using B as a lookahead. It would do this if 
  it has more than one alternative when it first time encounters elements of A on the stack - to reduce to A or to something else. 
  When parser has this conflict, it proceeds further reading the input, until it can reduce B, and then using B as a lookahead 
  it decides to reduce A. 
  The non-canonical parser implementation is very similar to canonical one. The main difference is the Reduce operation.
  The canonical LR/LALR parser pushes the newly created node into the parser stack. Non-canonical parser pushes 
  the new node back into the input stream, so it becomes a lookahead for the next parser step. The implementation 
  of non-canonical parser allows this push-back operation by having a structure called input stack that can accumulate
  pushed-back nodes. 
  

Roman, 4/11/2009