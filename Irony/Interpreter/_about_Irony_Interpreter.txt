
Some notes on Irony Interpreter implementation

Goals and non-goals 
1. Interpreter should be able to support more-less straightforward implementation of a typical dynamic/scripting languages like Python, Ruby or Lua - except maybe most fancy ones like continuations and co-routines (see below)
2. Interperter must be free-threaded - it should allow execution of scripts in parallel on multiple threads. Interpreter should not crash or "loose" data because of concurrent access from different threads. Note that we do mean to solve automatically the concurrency problems of scripting code: script author should use some locking mechanism to preserve integrity of complex data. But no matter what kind of actions script code performs on concurrent threads, the data is not corrupted or lost by the interpreter. 
3. And of course, we want a good performance. Good enough for implementations to compete with "native" implementations.  
4. Non-goals: this version of interpreter will not support such advanced features as continuations, co-routines, and fibers (light threads).   

Variables/values storage - some traditonal approaches
1. In scripting languages, the data elements (fields, properties, local variables) are created on the fly, on the first write. There's no pre-allocation at compile time. The set of variables is unknown in advance. Traditional, straightforward solution is to use a dictionary (string=>object) to store local variables of a function, or module-level variables. 
2. In free-threaded environment (and most scripting languages allow free-threaded execution), variables may be accessed from different threads. This means that the access to containing dictionaries should be performed using thread-locking mechanism, guaanteeing that only a single thread is accessing a dictionary.
So the script statement like:
  
  x = 5                        (1)

is translated into something like this:

  lock(scope) {                         (2)
    scope.Values["x"] = 5;                     
  }

Two important and disturbing facts. 
1. Dictionary  access is slow. At least if we mean .NET Dictionary<TKey, TValue> generic class. Simple tests coupled with source code inspection show that the cost is in the range of hundreds of processor instructions. 
2. Thread locking is slow.  The cost is also in the range of hundreds of instructions. Atomic operations using methods in Interlocked class are also slow.

The result is that implementation (2) is quite slow. Really slow, especially considering the fact that actual thread collisions on the same dictionary objects are quite rare, while we have to incur the extra cost of lock every time we read or write a value. 

What can be done better? 
Our interpreter stores data in linear arrays, and does NOT use thread locking when reading/writing the data. There is an explicit locking when we "create" a variable for the first time - we lock meta-data dictionary containing "descriptions" of data slots; all subsequent accesses to the variable values are done directly using an index. Before we explain how it works, we need to state an explicit assumption we rely on:

    Assumption: 
    Assignment of an object reference to a variable (ex: x = someObj) is an atomic operation and is "thread-safe"

So assignment can be safely done without thread locking. if one thread makes an assignment, and the other thread reads the reference, this other thread would see either old or new value, but never any "corrupted middle".

Irony implementation: arrays with no-lock read/write access.
 The data is stored in linear array of objects: Values[] field (see ScopeBase class). All access is done by index. When interpeter executes the first time an AST node that reads some variable x, it looks up a variable metadata (SlotInfo) in current scope metadata (ScopeInfo). The result is linear index of the data value in Values array. It then reads the value using the index: 
   vx = scope.Values[xSlotIndex];
all successive executions do the same but without looking up the SlotInfo - the xSlotIndex is cached in the node (more accurately, in SlotReader object). The problems comes when we need to resize the Values array because we are adding some local variable - for example, our script runs into new assignment statement in the local scope:

  y = 5

We need to add "y" to the list of slots (metadata), but then we also need to "extend" the Values[] array and add an extra element for "y". The question is: how to do resizing in such a way that if some other thread(s) is reading or writing other values in the same scope, it could finish it correctly even if it does this exactly at the moment when we resize the array?
Here's how we do it. Look at the ScopeBase.Resize method:

    protected void Resize(int newSize) {
      lock (this) {
        if (Values.Length >= newSize) return; 
        object[] tmp = Interlocked.Exchange(ref Values, null);
        Array.Resize(ref tmp, newSize);
        Interlocked.Exchange(ref Values, tmp);
      }
    }

We use Interlocked.Exchange to replace Values field with null as an atomic operation. We set the Values value to null in order to force any concurrent reads/writes to fail, if they happen at exactly this time. Now, in GetValue and SetValue methods, we expect this, and have a try/catch block to handle the null reference exception and retry the operation. Here's SetValues method:

    public void SetValue(int index, object value) {
      try {
        var tmp = Values;
        tmp[index] = value; 
        //Now check that tmp is the same as Values - if not, then resizing happened in the middle, 
        // so repeat assignment to make sure the value is in resized array.
        if (tmp != Values)
          SetValue(index, value); // do it again
      } catch (NullReferenceException) {
        Thread.Sleep(0); 
        SetValue(index, value); //repeat it again
      }  ..... 
    }//method

 The "catch" block for NullReferenceException is for handling the situation when Values was null while other thread was resizing it. Remember that try/catch block is free, it does not add any executable commands if we run without exception. 
There is additional twist here. It might happen that after we copied reference to array into tmp variable, some other thread resized the Values array - replacing it with new extended array. As a result, we are setting a value in a "dead" old array. To check against this, after we do value change, we check that "tmp" references the same object as Values field. If not, we got concurrent resize, so we repeat SetValue to make sure we set it in the new Values instance. 

As you can probably see, all variables are stored in object arrays, accessed by index, and accessed without explicit thread locks. The net result of this technique and some other improvements in new Interpreter is approximate 5-fold performance gain. 

NOW 5 TIMES FASTER!








